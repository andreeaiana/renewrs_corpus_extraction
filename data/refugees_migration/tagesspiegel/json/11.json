{"news_outlet": "tagesspiegel", "provenance": "https://www.tagesspiegel.de/gesellschaft/social-scoring-diese-systeme-kriechen-in-unseren-alltag/24098020.html", "query_keywords": ["migration"], "creation_date": "13.03.2019", "last_modified": "13.03.2019", "crawl_date": "23.11.2020", "author_person": ["Anna Sauerbrey"], "author_organization": [], "news_keywords": ["Interview", "Social_Credit", "Daten", "China", "Punkte", "Bewertungen", "Steffen_Mau"], "content": {"title": "\u201eDiese Systeme kriechen in unseren Alltag\u201c", "description": "Ob Bildung, Gesundheit oder Konsum: \u00dcberall werden Daten gesammelt und bewertet. Der Soziologe Steffen Mau untersucht das und zeigt im Interview die Folgen auf.", "body": {"": ["Dieses Interview ist ein Transkript der zweiten Folge unseres neuen Podcasts \u201eCausa \u2013 Der Ideenpodcast\u201c. Wir senden jeden Samstag ein neues Gespr\u00e4ch mit einem Wissenschaftler oder Publizisten zu den gro\u00dfen Fragen der Zeit. Das Gespr\u00e4ch wurde f\u00fcr die Schriftfassung aus Gr\u00fcnden der Lesbarkeit bearbeitet und gek\u00fcrzt.", "Herr Mau, die Politik beginnt gerade, sich mit Social Scoring zu besch\u00e4ftigen. Sie diskutieren dar\u00fcber an diesem Mittwoch mit Bundesjustizministerin Katarina Barley \u2013 Anlass ist die Er\u00f6ffnung der Ausstellung \u201eOpen Codes\u201c im Bundesjustizministerium. Was ist eigentlich Social Scoring?", "Eine Standarddefinition gibt es nicht. \u00dcbersetzt hei\u00dft das einfach Punktwerteverfahren, also der Versuch, soziale Ph\u00e4nomene oder die Eigenschaften von Personen mit Hilfe von Punktwerten zu beschreiben und damit vergleichbar zu machen. Eine ganz einfache Form ist die Vergabe von Punkten bei Sch\u00f6nheitswettbewerben. Aber wenn wir heute vom Scoring reden, meinen wir, dass gr\u00f6\u00dfere Datenmengen mit Hilfe von Algorithmen ausgewertet werden, um \u00fcber das Verhalten von Personen Auskunft zu geben, um sie zu klassifizieren, um vorherzusagen, was sie tun werden oder um ihren Marktwert zu beschreiben.", "In Deutschland bemerken viele Menschen das Social Scoring bislang bewusst ja vor allem, wenn sie ihre Kreditw\u00fcrdigkeit von der Schufa pr\u00fcfen lassen m\u00fcssen \u2013 dann wird aus verschiedenen Daten ein Wert ermittelt. Wenn wir uns anschauen wollen, was mit den enormen Datenmengen m\u00f6glich w\u00e4re, lohnt ein Blick nach China. China ist gerade dabei, ein \u201eSocial Credit System\u201c einzuf\u00fchren. Wie sieht das aus?", "Das System ist noch in der Entwicklung. Was aber heute schon klar ist, dass alle chinesischen B\u00fcrger einbezogen werden und die Daten aus sehr vielen unterschiedlichen Lebensbereichen zusammengef\u00fchrt werden sollen. Gro\u00dfe Internet-Unternehmen arbeiten daf\u00fcr sehr eng mit staatlichen Stellen zusammen. M\u00f6glicherweise wird es einen einzigen \u201eScore\u201c pro B\u00fcrger geben oder auch mehrere. Erfasst wird das Verhalten im \u00f6ffentlichen Raum, zum Beispiel, ob man seine B\u00fccher bei Bibliothek \u00fcberzieht. Bewertungen von Vorgesetzten und Vermietern flie\u00dfen ein, das Konsumverhalten im Internet, Regelverst\u00f6\u00dfe und \u00c4u\u00dferungen in Sozialen Medien.", "Das alles soll zu einer Art Klassifikations- und Bewertungssystem zusammengef\u00fchrt werden. Der oder die Score-Werte eines Menschen sind nicht nur informativ, sie sollen mit ganz konkreten Vor- oder Nachteilen verbunden sein. Wir wissen zum Beispiel, dass China auf dieser Basis im vergangenen Jahr schon 15 Millionen \u201eReiseverbote\u201c erteilt hat, also Leute mit einem schlechten Score von Fernreisen per Bahn oder Flugzeug ausgeschlossen hat. China ist eine Gesellschaft, wo viele Familien auf Grund der hohen Binnenmigration weit voneinander entfernt leben, daher ist das schon ein sehr starker Eingriff in die individuellen Freiheitsrechte."], "81 Prozent der Chinesen finden ein Social Credit-System gut": ["Warum f\u00fchrt China das System ein?", "Die chinesische F\u00fchrung sagt, es sei ein Instrument, um Vertrauen in einer Gesellschaft zu st\u00e4rken du eine \u201eMentalit\u00e4t der Ehrlichkeit\u201c herzustellen. In einer Gesellschaft, in der sich viele disruptive Ver\u00e4nderungen abspielen \u2013 hohe Binnenmigration, neue Ungleichheiten, Individualisierung \u2013, scheint es daf\u00fcr eine Nachfrage zu geben, von den politischen Kontrollambitionen ganz zu schweigen. Aber echtes Vertrauen w\u00e4re ja gerade, wenn es keine Kontrolle braucht. Hier wird der Machtanspruch des sozialistischen Einpaarteienstaates mit den Mitteln der digitalen Revolution verbunden.", "K\u00fcrzlich hat die China-Expertin Mareike Ohlberg in einem Gespr\u00e4ch mit dem Magazin \u201eWired\u201c gesagt, das chinesische System sei sicherlich einzigartig. Andererseits sei es aber auch Teil eines \u201eglobalen Trends\u201c zum Social Scoring - auch in westlichen Demokratien. Teilen Sie diese Einsch\u00e4tzung?", "Im Prinzip ja. Es gibt einen zentralen Unterschied: Politische Akteure in China haben die M\u00f6glichkeit, sehr zentral auf sehr viele Daten zuzugreifen. Das ist in westlichen Gesellschaften nicht der Fall, hier sind es oft privatwirtschaftliche Unternehmen, die die Daten sammeln. Und es gibt gro\u00dfe Unterschiede in der gesellschaftlichen Sensibilit\u00e4t f\u00fcr die Verwendung und Verwertung der Daten.", "Eine Kollegin von der Freien Universit\u00e4t hier in Berlin, Genia Kostka, hat chinesische B\u00fcrger befragt, wie sie solche Systeme finden. Etwa 81 Prozent haben gesagt, sie finden das gut. 18 Prozent waren unentschieden, nur 1,5 Prozent lehnen das ab. Die Umfragen bei uns \u2013 da gibt es jetzt zwei Studien \u2013 sagen, dass nur rund ein F\u00fcnftel bis ein Sechstel der Bev\u00f6lkerung solchen Systemen etwas abgewinnen k\u00f6nnen. De facto aber kriechen diese Systeme auch in unseren Alltag."], "In Gro\u00dfbritannien werden mit Daten Problemfamilien identifiziert": ["K\u00f6nnen Sie Beispiele nennen?", "Gerade ist eine Studie der Bertelsmann-Stiftung erschienen, die f\u00fcr Europa untersucht, wie staatliche Beh\u00f6rden mit den Daten der B\u00fcrger arbeiten, beispielsweise im Bereich der sozialen Dienstleistungen, bei der Polizei oder im Rechtswesen. In kommunalen Kontexten in Gro\u00dfbritannien werden zum Beispiel Daten \u00fcber die Bibliotheksleihe und das Parkverhalten im \u00f6ffentlichen Raum mit Informationen zu Steuerschulden oder Sozialleistungsbezug zusammengef\u00fchrt. In manchen F\u00e4llen geht es darum, anhand von Beh\u00f6rdendaten Problemfamilien zu erkennen.", "\u00d6sterreich wiederum hat ein System entwickelt, dass beurteilt, wer gute und wer schlechte Chancen auf dem Arbeitsmarkt hat, um zu entscheiden, f\u00fcr wen es lohnt, Fortbildungsma\u00dfnahmen zu bezahlen. In den USA gibt es Scores, die anhand von Aufenthalten in Arztpraxen, Einreichungen bei der Krankenkasse, Verschreibungen, aber auch von Wohnortdaten bewerten, ob jemand ein erh\u00f6htes Risiko hat, drogenabh\u00e4ngig zu werden: Diese Menschen werden dann mit Hilfsangeboten besonders angesprochen.", "Manchmal sind die Entscheidungen der Algorithmen recht drastisch. In Kalifornien entscheidet Algorithmen anhand von \u201eRisikoscores\u201c, ob ein Angeklagter auf Kaution freigelassen wird oder nicht\u2026", "Ja, vieles von dem, was wir so machen, wird verwertbar \u2013 und f\u00fchrt dazu, dass uns Chancen offenstehen oder eben auch nicht. Auch Privatunternehmen setzen ja zunehmend auf Scoring-Daten. Ein neues Beispiel sind Vermieterplattformen in den USA: Vermieter zentralisieren Daten dar\u00fcber, wer wie schnell zahlt oder anderen Aufforderungen nachkommt und diese Menschen bekommen dann Vorteile bei bestimmten Dienstleistungen, die in einem Mietshaus angeboten werden. Man orientiert sich dann bei Handwerkerterminen st\u00e4rker an den Arbeitszeiten der Menschen mit guten \u201eScores\u201c."], "Grenzkontrollen und Sicherheitschecks werden automatisiert": ["In Europa f\u00fchlen wir uns noch einigerma\u00dfen gesch\u00fctzt durch unsere strengen Datenschutzregeln\u2026", "Ja, aber der Datenmarkt ist international. In den USA gibt es Daten-Broker, die von \u00fcber der H\u00e4lfte der Deutschen mittels \u201eMarktklassifikationsdaten\u201c erfasst haben und diese auch an Dritte weiterverkaufen. An vielen Stellen werden Daten von Ihnen erfasst, ohne, dass Sie einen Einfluss darauf haben. Ich besch\u00e4ftige mich derzeit zum Beispiel mit \u201eSmart Borders\u201c, mit \u201eintelligenten Grenzen\u201c, Grenzen, an denen Grenzkontrollen und Sicherheitschecks automatisiert werden. Da werden biometrische Daten genommen, zum Beispiel ein Iris-Scan oder ein Fingerabdruck, das wird kombiniert mit Daten aus anderen Quellen.", "Wir beobachten auch, dass Scoring-Systeme l\u00e4nder\u00fcbergreifend eingesetzt werden. In China zum Beispiel ist ein wichtiger Kreditscore der \u201eZhima-Credit\u201c, der erfasst nicht nur die finanzielle Bonit\u00e4t, sondern auch Lebensweisen, Aktivit\u00e4ten, Konsumgewohnheiten. Kanada hat nun mit China einen Vertrag abgeschlossen, der besagt, dass Menschen, die sich um ein kanadisches Visum bewerben, nicht mehr einen Kontoauszug einreichen m\u00fcssen, sondern sich mit diesem Score bewerben k\u00f6nnen. Ab einer bestimmten H\u00f6he hat man als chinesischer B\u00fcrger erleichterten Zugang nach Kanada.", "In Ihrem Buch schreiben Sie, dass Social Scores eine Art \u201esoziale Platzanweiserfunktion\u201c in der Gesellschaft bekommen. Was meinen Sie damit?", "Ich gebe Ihnen ein Beispiel: 2018 war ich ein halbes Jahr in den USA, dort haben wir \u00fcber eine Webseite einen Babysitter gesucht. Die Babysitter konnte man nat\u00fcrlich einerseits bewerten \u2013 dadurch entstand ein Ranking. Man konnte zus\u00e4tzlich \u00fcber ein System namens \u201eMyLife.com\u201c auch die Reputation der Person abfragen. Man klickt, dann r\u00f6delt das System ein bisschen und schaut alles durch: Wohnort, Aliasnamen, Social Media Accounts, Geschwindigkeits\u00fcbertretungen, ob jemand in Besitz einer Schusswaffe ist, Verschuldung, Sittlichkeitsdelikte, anh\u00e4ngige und fr\u00fchere Gerichtsprozesse. In den USA sind das gr\u00f6\u00dftenteils \u00f6ffentliche Daten.", "Das alles wird zu einem Reputationsscore zusammengef\u00fchrt \u2013 wie genau, dar\u00fcber konnte man nichts erfahren. Aber eine Babysitterin mit einem Score von nur 2,3 auf einer Skala von f\u00fcnf w\u00fcrde man wahrscheinlich nicht nehmen. So entsteht \u201esoziales Kapital\u201c, das hei\u00dft, dass man Reputation in andere Arten von Vorteilen umtauschen kann, materielle Vorteile, Marktvorteile."], "Algorithmen sind Gesch\u00e4ftsgeheimnis": ["Diejenigen, die die Algorithmen programmieren und die die Skala festlegen erhalten so viel Macht. Sie verwenden in Ihrem Buch f\u00fcr diese Form der Macht den Begriff der \u201eBenennungsmacht\u201c, ein Begriff von Pierre Bourdieu\u2026", "Bourdieu ist immer davon ausgegangen, dass die Benennungsmacht beim Staat liegt, er dachte an die Zertifizierung, das Urkundenwesen. Jetzt geht die Benennungsmacht teilweise vom Staat auf private Unternehmen \u00fcber \u2013 auch sie k\u00f6nnen wirkm\u00e4chtig klassifizieren. Wer in welche Kategorie f\u00e4llt \u2013 kreditw\u00fcrdig oder nicht, gesund oder krank \u2013 das liegt ganz stark an den Messverfahren, an den Indikatoren und an den Apps, mit denen gemessen werden.", "Sie bestimmen aber nicht nur \u00fcber die Kategorie, in die ein Einzelner f\u00e4llt. Sie bestimmen auch, welche Art von Welt uns als Gesellschaft insgesamt erscheint. Es werden neue \u201eSichtbarkeitsordnungen\u201c kreiert. Die Welt wird nicht einfach abgebildet \u2013 sie wird reformatiert. Diese neue Welt ist nicht v\u00f6llig losgekoppelt von dem, was da drau\u00dfen ist. Aber die Scores stellen doch nur ein sehr spezifisches Bild unserer Welt dar.", "Welche Folgen hat das?", "Die Benennungsmacht wird immer st\u00e4rker privatisiert \u2013 und es entstehen neue Machtgef\u00e4lle. Die Unternehmen sagen: Die Algorithmen sind unser Gesch\u00e4ftsgeheimnis. Wir aber werden immer gl\u00e4serner. Sie sind der \u00f6ffentlichen Kontrolle entzogen, wirken aber dennoch sehr stark in die Gesellschaft hinein. Das ist eine gef\u00e4hrliche Situation und ver\u00e4ndert die Art und Weise, wie wir Gesellschaft denken und organisieren.", "Wenn Algorithmen Entscheidungen treffen, kann es auch leicht zu Diskriminierungen kommen. Es hat sich zum Beispiel gezeigt, dass Frauen in dem \u00f6sterreichischen System zur automatischen Klassifizierung von Arbeitslosen, das Sie schon erw\u00e4hnt haben, weniger Fortbildungsma\u00dfnahmen erhalten als M\u00e4nner. Die Arbeitslosen werden in drei Kategorien eingeteilt: Solche, die besonders gute Chancen am Arbeitsmarkt haben, solche, die besonders schlechte Chancen haben und eine Mitte. Die in der mittleren Kategorie sollen besonders gef\u00f6rdert werden \u2013 und in dieser Kategorie finden sich Frauen seltener.", "Selbst wenn in diesen Algorithmen die Kategorien \u201eGeschlecht\u201c oder \u201eAlter\u201c gar keine Rolle spielen, kann es sein, dass indirekt, durch die Hintert\u00fcr, sozusagen \u201eaus Versehen\u201c, doch danach gefiltert wird. Ob das nun Diskriminierung ist oder Differenzierung, ist gar nicht so leicht zu sagen, zun\u00e4chst wird ja \u201enur\u201c unterschieden. Aber es kommt auch zu sich selbst verst\u00e4rkenden Effekten \u2013 und dann kann Diskriminierung einsetzen. In den USA zum Beispiel haben Schwarze statistisch eine h\u00f6here Wahrscheinlichkeit, kriminell zu werden.", "Wenn man dann Risikoscores f\u00fcr bestimmte Stadtviertel entwickelt, wird die Polizei aktiver in Gebieten, in denen viele Schwarze wohnen. Damit steigt wiederum die Wahrscheinlichkeit, bei einer Straftat erwischt zu werden, der Score verschlechtert sich weiter. In vielen Bereichen haben wir uns in Deutschland ja deshalb bewusst gegen Differenzierung entschieden. Bei der Krankenversicherung wird nicht zwischen M\u00e4nnern und Frauen unterschieden oder zwischen Rauchern und Nichtrauchern. Wir wissen, dass es Unterschiede gibt. Aber wir wollen nicht, dass sie Teil der Risikoklassifikation und der Preisberechnung werden."], "Freiwillige Komplizen des \u00dcberwachungskapitalismus": ["Trotz aller dieser Bedenken \u2013 die Dystopie China, das Wissen \u00fcber m\u00f6gliche Diskriminierung \u2013 machen viele Menschen beim Social Scoring freiwillig mit. Ich selbst messe auch mit einer Laufapp, wie viel und wie weit ich gelaufen bin und teile das in meinem Freundeskreis auf Facebook. Warum mache ich das eigentlich?", "Ich k\u00f6nnte jetzt \u00fcber Sie die Nase r\u00fcmpfen, aber ich mache das selbst auch. Nein, im Ernst. Ich nenne es das \u201ekalte Charisma der Zahlen\u201c. Zahlen haben eine gewisse Attraktivit\u00e4t, weil sie objektiv und neutral erscheinen. Menschen haben ein Interesse daran, auf objektive Daten zur\u00fcckzugreifen, um festzustellen, wer sie sind und wo sie stehen. Das ist eine Form der Statusbestimmung, die auch beruhigend wirken kann. Viele Medizinapps sind weit davon entfernt, gute Prognosen abzugeben, versprechen aber ein l\u00e4ngeres Leben, wenn man sich damit selbst kontrolliert.", "In vielen Bereichen w\u00e4ren wir au\u00dferdem aus der digitalen Welt ausgeschlossen, wenn wir nicht in irgendeiner Weise als Datengeneratoren daran teilnehmen. Die Kosten des \u201edigital detox\u201c sind relativ hoch, das ist eine Form der Selbstexklusion. Deshalb sind wir freiwillige Komplizen des \u00dcberwachungskapitalismus \u2013 auch, wenn uns das in ein st\u00e4ndiges Strampeln f\u00fchrt.", "Muss uns die Politik deshalb helfen \u2013 brauchen wir politische Regulierung?", "Die Regulierung ist schwierig. In den Unternehmen sagen die Leute: Europa ist schon so streng reguliert was die \u201eBewirtschaftung\u201c von Daten angeht, wir haben daraus Wettbewerbsnachteile. Andererseits ist die Verschiebung, die wir beobachten, extrem. Wenn man gar nicht reguliert, wird uns die Benennungsmacht vollst\u00e4ndig entrissen werden. Sie wird in die H\u00e4nde der gro\u00dfen Internetgiganten wandern. Wenn wir diese Entwicklung verhindern wollen, m\u00fcssen wir uns emanzipieren und an der einen oder anderen Stelle harsch politisch intervenieren. Wir k\u00f6nnen nicht zulassen, dass die Lebenschancen von Algorithmen bestimmt werden."], "Betroffene sollten beteiligt und repr\u00e4sentiert sein": ["Gruselig ist ja vor allem die Vorstellung, dass ein Programm \u00fcber mich entscheidet, ohne, dass ich wei\u00df, wie die Entscheidung zustande gekommen ist \u2013 und ohne, dass ich eine Einspruchsm\u00f6glichkeit habe. W\u00e4ren nicht Transparenz und verpflichtende Widerspruchsverfahren ein wichtiger erster Schritt?", "Das Bundesjustizministerium hat vom Sachverst\u00e4ndigenrat f\u00fcr Verbraucherfragen ein Gutachten erstellen lassen, das Ende 2018 ver\u00f6ffentlich wurde \u2013 und da wird genau so etwas vorgeschlagen. Die Algorithmen m\u00fcssen \u201etestbar\u201c sein, meinen die Gutachter. Das hei\u00dft, die Unternehmen m\u00fcssten nicht unbedingt den Quellcode offenlegen \u2013 den sie ja als Betriebsgeheimnis betrachten \u2013 aber sie m\u00fcssten die Merkmale, die eingehen, transparent machen und Testm\u00f6glichkeiten anbieten.", "Auch eine \u201eDigitalagentur\u201c wird vorgeschlagen, die \u00fcberwacht, in welchen Bereichen solche Algorithmen eingesetzt werden und ob Fairness- und Gleichheitsanspr\u00fcche eingehalten werden. Ich w\u00fcrde noch einen Schritt weitergehen. In den Unternehmen und Beh\u00f6rden, die solche Algorithmen entwickeln, m\u00fcssen Betroffene beteiligt und repr\u00e4sentiert sein. Au\u00dferdem muss es noch einfacher sein, die eigenen Daten l\u00f6schen zu k\u00f6nnen und man sollte leichter die Verwendung der eigenen Daten beschr\u00e4nken k\u00f6nnen \u2013 zum Beispiel, um den Verkauf der Daten an Dritte verhindern."]}}, "recommendations": ["https://www.tagesspiegel.de/themen/podcasts/causa-der-ideenpodcast-folge-2-die-vermessung-unserer-lebenswelt/24082756.html"]}